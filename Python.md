语言规范
--------

### 程序结构

1.  引用原生库和手写库

2.  定义全局变量

3.  定义修饰器

4.  定义类（包括函数对象）

5.  定义函数（包括`argparse`）

6.  定义主函数

语言特点
--------

### 易错点

1.  不要将`Python`源码文件命名为包的名字，否则会因重复包含导致错误

### 运行特点

1.  在使用`import`时正确的路径是针对`main.py`而言的，而不是针对当前文件而言的

2.  `global`关键字的使用是为了在局部作用域中引用并修改全局变量

3.  闭包函数若要修改上级作用域中的变量，需要用`nonlocal`关键字

4.  `Python`中只有模块(`module`)，类(`class`)以及函数(`def`、`lambda`)才会引入新的作用域，其它的代码块(如`if`、`try`、`for`等)不会引入新的作用域，因此在代码块外部可以直接引用代码块内声明的变量

5.  `Python`的变量是动态声明的，未考虑到这点可能出现`bug`，例如在`if`语句中声明了变量，若该`if`语句条件为假，则不仅其内部语句不执行，其内部变量也不会被定义。因此，很多时候有必要在`if`语句之前声明变量

包
--

### re

1.  在?、+、\*以及{n,m}后加?表示进行懒惰匹配（与默认的贪婪匹配相反）

2.  `\b`、^、$匹配的是单词边界，而非字符（匹配的是"一条线"）

### numpy

1.  在`numpy`中，不同函数有的返回的是副本，有的返回的是视图，需要区分，可以用`base`属性来进行查看

2.  `indexing`为视图而`fancy_indexing`为副本

### torch

1.  `torch`中大写首字母（`Class`）与小写首字母（`Function`）在用法上有区别，功能基本相同
2.  `indexing`为视图而`fancy_indexing`为副本
3.  所有下划线操作直接操作原变量
4.  可以对非叶节点依次使用`detach_`和`requires_grad_`方法，使该非叶节点变为求导的对象
5.  `torch`无法实现对矢量结果的自动求导，需要人为输入一个外部梯度来进行计算
6.  `torch.nn`不支持单样本输入，例如`CNN`中卷积函数接受的张量为`4`维（`batch_size`\*`channels`\*`height`\*`weight`）
7.  在不进行训练时，使用神经网络不开启梯度，即使用`with torch.no_grad():`包裹代码
8.  `torch`在使用多`GPU`并行训练时可以自动划分任务并分配给每个`GPU`